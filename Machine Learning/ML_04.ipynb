{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PnneyEDMVM1"
      },
      "source": [
        "----\n",
        "# Cuaderno 4 - División de datos y validación cruzada\n",
        "## Ariel Palazzesi - 2026\n",
        "----\n",
        "\n",
        "En este cuaderno vamos a aprender:\n",
        "\n",
        "- Cómo dividir el dataset en conjuntos de entrenamiento y prueba.\n",
        "- Cómo entrenar un modelo simple y detectar posibles casos de *overfitting* o *underfitting*.\n",
        "- Cómo aplicar validación cruzada para obtener una evaluación más robusta del modelo.\n",
        "\n",
        "La idea es experimentar con los datos de forma práctica y reflexiva.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7unSIevMY-I"
      },
      "source": [
        "## Cómo usar el dataset\n",
        "\n",
        "En este cuaderno usamos el archivo `Titanic-Dataset.csv`. Para cargarlo en Colab:\n",
        "\n",
        "1. Hacé clic en el ícono de la carpeta en el margen izquierdo.\n",
        "2. Subí el archivo `Titanic-Dataset.csv` desde tu computadora.\n",
        "3. Verificá que aparezca en la carpeta `/content/`.\n",
        "\n",
        "Luego, ejecutá el siguiente bloque de código para cargar los datos y comenzar a trabajar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gm6YKYIcL-0Z",
        "outputId": "ae6683c7-7b36-4572-d4a2-0625b602f0d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Estilo general para los gráficos\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "\n",
        "# Cargamos el dataset\n",
        "# df = pd.read_csv(\"/content/Titanic-Dataset.csv\")\n",
        "df = pd.read_csv(\"Titanic-Dataset.csv\")\n",
        "\n",
        "# Mostramos las primeras filas\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K7bde7cM6ZS"
      },
      "source": [
        "## Selección de variables para el modelo\n",
        "\n",
        "Antes de entrenar cualquier modelo, es importante seleccionar qué columnas vamos a utilizar como **características predictoras** (también llamadas *features*) y cuál será nuestra **variable objetivo** o *target*.\n",
        "\n",
        "En este ejemplo, vamos a predecir si una persona sobrevivió al hundimiento del Titanic. Por lo tanto, la variable objetivo será `Survived`, que contiene un 0 si no sobrevivió y un 1 si sí lo hizo.\n",
        "\n",
        "Como características predictoras, vamos a usar algunas variables que ya fueron transformadas en cuadernos anteriores (por ejemplo, codificación de variables categóricas y escalado de numéricas). Para simplificar este ejemplo, seleccionaremos algunas de las más limpias y representativas:\n",
        "\n",
        "- `Pclass_encoded`: clase del pasajero (ya codificada como 0, 1, 2)\n",
        "- `Sex`: género del pasajero (vamos a codificarla a continuación)\n",
        "- `Age_normalizada`: edad escalada\n",
        "- `Fare_normalizada`: tarifa escalada\n",
        "- `Embarked_C`, `Embarked_Q`, `Embarked_S`: variables dummy creadas a partir del puerto de embarque\n",
        "\n",
        "> Si no tenés estas columnas listas desde los caudernosanteriores, no te preocupes: podés agregar solo algunas de ellas o adaptarlas con las transformaciones que ya hayas practicado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kCCtNWvRM8og",
        "outputId": "dd2740df-90f0-4185-95db-d5eb2f34150e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex_encoded</th>\n",
              "      <th>Age_normalizada</th>\n",
              "      <th>Fare_normalizada</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass  Sex_encoded  Age_normalizada  Fare_normalizada  Embarked_C  \\\n",
              "0       3            0         0.271174          0.014151       False   \n",
              "1       1            1         0.472229          0.139136        True   \n",
              "2       3            1         0.321438          0.015469       False   \n",
              "3       1            1         0.434531          0.103644       False   \n",
              "4       3            0         0.434531          0.015713       False   \n",
              "\n",
              "   Embarked_Q  Embarked_S  \n",
              "0       False        True  \n",
              "1       False       False  \n",
              "2       False        True  \n",
              "3       False        True  \n",
              "4       False        True  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Para este ejemplo, creamos una copia del dataset original\n",
        "df_modelo = df.copy()\n",
        "\n",
        "# Codificamos la variable 'Sex' manualmente\n",
        "df_modelo['Sex_encoded'] = df_modelo['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Aplicamos One-Hot Encoding a 'Embarked' (si no fue hecho aún)\n",
        "embarked_dummies = pd.get_dummies(df_modelo['Embarked'], prefix='Embarked', drop_first=False)\n",
        "df_modelo = pd.concat([df_modelo, embarked_dummies], axis=1)\n",
        "\n",
        "# Escalamos 'Age' y 'Fare' si no están escaladas\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df_modelo[['Age_normalizada', 'Fare_normalizada']] = scaler.fit_transform(df_modelo[['Age', 'Fare']])\n",
        "\n",
        "# Definimos X (features) e y (target)\n",
        "columnas_features = ['Pclass', 'Sex_encoded', 'Age_normalizada', 'Fare_normalizada',\n",
        "                     'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
        "X = df_modelo[columnas_features]\n",
        "y = df_modelo['Survived']\n",
        "\n",
        "# Mostramos las primeras filas\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbSmNtbYNFWK"
      },
      "source": [
        "## División en conjuntos de entrenamiento y prueba\n",
        "\n",
        "Una vez que tenemos listas nuestras variables predictoras (`X`) y nuestra variable objetivo (`y`), el siguiente paso es dividir el dataset en dos partes:\n",
        "\n",
        "- Un conjunto de **entrenamiento**, que se usará para ajustar el modelo.\n",
        "- Un conjunto de **prueba**, que se usará para evaluar si el modelo funciona bien con datos que no vio durante el entrenamiento.\n",
        "\n",
        "Esta división nos permite simular un entorno real: queremos que el modelo aprenda con un conjunto de datos, y luego comprobar si puede generalizar lo aprendido a nuevos casos.\n",
        "\n",
        "Vamos a usar una división clásica: **80% para entrenamiento y 20% para prueba**, utilizando la función `train_test_split` de `scikit-learn`, que realiza esta separación de forma aleatoria pero reproducible si se fija una semilla (`random_state`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYKlgqa2P7c6"
      },
      "source": [
        "## Eliminación de valores faltantes\n",
        "\n",
        "Antes de entrenar nuestro modelo, debemos asegurarnos de que no haya valores faltantes (NaN) en las columnas que vamos a utilizar. Muchos algoritmos de `scikit-learn`, como la `Regresión Logística`, no pueden trabajar con datos incompletos.\n",
        "\n",
        "En este caso, algunas variables como `Age` o `Embarked` pueden tener valores vacíos. Para resolverlo de forma sencilla, vamos a eliminar todas las filas que tengan al menos un valor faltante en las columnas seleccionadas para el modelo.\n",
        "\n",
        "En cuadernos futuros veremos otras técnicas más avanzadas para tratar datos faltantes, como la imputación automática o el uso de modelos que aceptan NaN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01i-SN38P-On",
        "outputId": "a43c0969-f7d1-466e-b273-2c184686a329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¿Hay NaN en X? False\n",
            "¿Hay NaN en y? False\n"
          ]
        }
      ],
      "source": [
        "# Combinamos X e y para eliminar filas incompletas\n",
        "df_modelo_clean = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Eliminamos filas con valores NaN\n",
        "df_modelo_clean = df_modelo_clean.dropna()\n",
        "\n",
        "# Separamos nuevamente X e y\n",
        "X = df_modelo_clean[columnas_features]\n",
        "y = df_modelo_clean['Survived']\n",
        "\n",
        "# Verificamos que no queden valores faltantes\n",
        "print(\"¿Hay NaN en X?\", X.isna().sum().sum() > 0)\n",
        "print(\"¿Hay NaN en y?\", y.isna().sum() > 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bthMxEGRNJH2",
        "outputId": "bb3c9191-be89-463a-dcad-8083af34661e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos de entrenamiento: (571, 7)\n",
            "Datos de prueba: (143, 7)\n"
          ]
        }
      ],
      "source": [
        "# Dividimos los datos en entrenamiento (80%) y prueba (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Verificamos las formas de los conjuntos\n",
        "print(f\"Datos de entrenamiento: {X_train.shape}\")\n",
        "print(f\"Datos de prueba: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMH6kxZWNieO"
      },
      "source": [
        "## Entrenamiento de un modelo simple: Regresión Logística\n",
        "\n",
        "Una vez que los datos fueron preparados y divididos en conjuntos de entrenamiento y prueba, podemos avanzar hacia el **entrenamiento de nuestro primer modelo de Machine Learning**.\n",
        "\n",
        "En este caso utilizaremos **Regresión Logística**, un algoritmo clásico para problemas de **clasificación binaria**, es decir, situaciones donde la variable objetivo solo puede tomar dos valores posibles (por ejemplo, *sí/no*, *0/1*, *sobrevive/no sobrevive*).\n",
        "\n",
        "> **NOTA:** Aunque su nombre contiene la palabra *regresión*, la regresión logística se utiliza para **clasificar**. El modelo aprende una relación entre las variables de entrada y la probabilidad de pertenecer a una de las dos clases, y luego decide la clase final a partir de esa probabilidad.\n",
        "\n",
        "Este modelo es una buena elección para comenzar porque:\n",
        "\n",
        "* es simple y rápido de entrenar,\n",
        "* suele funcionar bien como línea base,\n",
        "* y sus resultados son relativamente fáciles de interpretar.\n",
        "\n",
        "En el código de la celda siguiente, se importa primero la clase `LogisticRegression` desde `sklearn.linear_model`, que permite crear el modelo, y la función `accuracy_score` desde `sklearn.metrics`, que se utilizará para evaluar su rendimiento.\n",
        "\n",
        "Al crear el modelo con `LogisticRegression(max_iter=1000)`, el argumento `max_iter` indica la cantidad máxima de iteraciones que el algoritmo puede realizar durante el proceso de entrenamiento. Aumentar este valor ayuda a asegurar que el modelo encuentre una solución adecuada, especialmente cuando el dataset es más complejo.\n",
        "\n",
        "Luego, el método `fit(X_train, y_train)` entrena el modelo utilizando los datos de entrenamiento. En este paso, el algoritmo ajusta sus parámetros internos para aprender la relación entre las variables predictoras (`X_train`) y la variable objetivo (`y_train`).\n",
        "\n",
        "Una vez entrenado el modelo, se realizan predicciones tanto sobre el conjunto de entrenamiento como sobre el conjunto de prueba utilizando el método `predict()`. Esto permite obtener:\n",
        "\n",
        "* `y_pred_train`: las predicciones del modelo sobre los datos con los que fue entrenado,\n",
        "* `y_pred_test`: las predicciones sobre datos que el modelo no vio durante el entrenamiento.\n",
        "\n",
        "Finalmente, se calcula la **precisión** (*accuracy*) en ambos conjuntos mediante la función `accuracy_score()`. Esta métrica indica qué proporción de predicciones fue correcta. Comparar la precisión en entrenamiento y en prueba es fundamental para evaluar cómo generaliza el modelo:\n",
        "\n",
        "* si la precisión es muy alta en entrenamiento pero baja en prueba, puede haber **sobreajuste**,\n",
        "* si ambas precisiones son bajas, puede haber **subajuste**,\n",
        "* si ambas son similares y razonables, el modelo está generalizando correctamente.\n",
        "\n",
        "El objetivo de este primer modelo no es lograr el mejor rendimiento posible, sino **entender el proceso completo de entrenamiento, predicción y evaluación**, que será la base para trabajar con modelos más complejos en etapas posteriores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCOm83w7NrBU",
        "outputId": "94b0579d-afc4-4178-c54c-ceb3f4ae4a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión en entrenamiento: 0.8039\n",
            "Precisión en prueba: 0.7552\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Creamos y entrenamos el modelo\n",
        "modelo = LogisticRegression(max_iter=1000)\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_train = modelo.predict(X_train)\n",
        "y_pred_test = modelo.predict(X_test)\n",
        "\n",
        "# Evaluamos la precisión en entrenamiento y prueba\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"Precisión en entrenamiento: {accuracy_train:.4f}\")\n",
        "print(f\"Precisión en prueba: {accuracy_test:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_h8YXB6Nmj4"
      },
      "source": [
        "## ¿Cómo interpretamos estos resultados?\n",
        "\n",
        "La **precisión** es una métrica simple que indica el porcentaje de predicciones correctas realizadas por el modelo.\n",
        "\n",
        "En este ejemplo, comparamos la precisión sobre el conjunto de entrenamiento y el conjunto de prueba. Si la precisión en entrenamiento es muy alta pero baja en prueba, es probable que estemos ante un caso de **sobreajuste**: el modelo aprendió demasiado los datos que ya conocía, pero no generaliza bien a casos nuevos.\n",
        "\n",
        "Si la precisión es baja en ambos conjuntos, probablemente el modelo no está capturando bien los patrones, lo que indica un posible **subajuste**.\n",
        "\n",
        "Y si la precisión es razonablemente buena y similar en ambos conjuntos, significa que el modelo está logrando un buen equilibrio: **aprende, pero no memoriza**.\n",
        "\n",
        "> Podés experimentar con otras proporciones de train/test o con diferentes variables para ver cómo cambian los resultados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_3Ld0j-QbnT"
      },
      "source": [
        "## Validación cruzada con K-Fold\n",
        "\n",
        "Hasta ahora evaluamos el modelo utilizando una única división de los datos en conjunto de entrenamiento y conjunto de prueba. Si bien este enfoque es sencillo y muy usado, tiene una limitación importante: **los resultados pueden variar según cómo se haya realizado esa división**. Una partición distinta de los datos podría dar una precisión mayor o menor, sin que el modelo haya cambiado realmente.\n",
        "\n",
        "La **validación cruzada** permite reducir este problema y obtener una evaluación más confiable del modelo. La idea central es dividir el conjunto de datos en varios grupos llamados *pliegues* (*folds*) y entrenar el modelo varias veces. En cada iteración, uno de los pliegues se utiliza como conjunto de validación y los restantes se usan para entrenar el modelo. De esta forma, **todos los datos se usan tanto para entrenar como para evaluar**, pero en momentos distintos.\n",
        "\n",
        "En el código se utiliza la función `cross_val_score()` de `sklearn.model_selection`. Esta función se encarga automáticamente de:\n",
        "\n",
        "* dividir los datos en pliegues,\n",
        "* entrenar el modelo múltiples veces,\n",
        "* evaluar el rendimiento en cada iteración.\n",
        "\n",
        "El primer argumento de `cross_val_score()` es el modelo que queremos evaluar (`modelo`). Luego se pasan las variables predictoras `X` y la variable objetivo `y`. El parámetro `cv=5` indica que se utilizará una validación cruzada de **5 pliegues (5-Fold)**, una configuración muy común en la práctica. Esto significa que el modelo se entrenará y evaluará cinco veces, cada vez usando un pliegue distinto como conjunto de validación.\n",
        "\n",
        "El argumento `scoring='accuracy'` define la métrica que se utilizará para evaluar el modelo en cada pliegue. En este caso se utiliza la **precisión (accuracy)**, que mide la proporción de predicciones correctas.\n",
        "\n",
        "El resultado de `cross_val_score()` se guarda en la variable `scores`, que contiene un arreglo con la precisión obtenida en cada uno de los pliegues. Mostrar estos valores permite observar cómo varía el rendimiento del modelo según el subconjunto de datos utilizado para validación.\n",
        "\n",
        "Y al final se calcula la **precisión promedio** utilizando `scores.mean()`. Este valor resume el desempeño general del modelo y suele ser una medida más **robusta y estable** que la obtenida con una sola partición entrenamiento-prueba.\n",
        "\n",
        "El objetivo de aplicar validación cruzada en este punto es obtener una evaluación más confiable del modelo y reducir la posibilidad de sacar conclusiones basadas en una división particular de los datos que haya sido favorable o desfavorable por casualidad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwN9yjkMQdD7",
        "outputId": "a2f7d1d8-498d-4878-b441-79cc5e1c2995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión en cada pliegue:\n",
            "[0.72027972 0.83916084 0.76223776 0.75524476 0.81690141]\n",
            "\n",
            "Precisión promedio (cross-validation): 0.7788\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Aplicamos validación cruzada de 5 pliegues\n",
        "scores = cross_val_score(modelo, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Precisión en cada pliegue:\")\n",
        "print(scores)\n",
        "\n",
        "print(f\"\\nPrecisión promedio (cross-validation): {scores.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XIaEVaRQgBL"
      },
      "source": [
        "## ¿Qué nos dice la validación cruzada?\n",
        "\n",
        "En los resultados anteriores, cada número representa la precisión del modelo en una partición distinta del dataset. El promedio de estas precisiones nos da una idea más confiable del rendimiento real del modelo, ya que no depende de una única división de los datos.\n",
        "\n",
        "Si los valores de precisión son muy diferentes entre sí, eso puede indicar que el modelo es **sensible a los datos con los que se entrena**, lo cual es una señal de alerta.\n",
        "\n",
        "Si, en cambio, los valores son parecidos y estables, podemos confiar más en la evaluación y utilizar ese promedio como una referencia sólida para comparar modelos en el futuro.\n",
        "\n",
        "Este tipo de evaluación más robusta será fundamental más adelante, cuando empecemos a construir, comparar y ajustar distintos algoritmos de Machine Learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcNQJ2YeQ8Hw"
      },
      "source": [
        "## Conclusión y cierre\n",
        "\n",
        "En este cuaderno recorrimos uno de los pasos más importantes en cualquier proyecto de Machine Learning: **evaluar correctamente el rendimiento del modelo**. Aprendimos a dividir los datos en conjuntos de entrenamiento y prueba, y vimos cómo aplicar **validación cruzada** para obtener resultados más robustos y confiables.\n",
        "\n",
        "También entrenamos un modelo simple, observamos su comportamiento sobre diferentes conjuntos de datos, y detectamos cómo la forma en que dividimos la información puede influir en la interpretación del rendimiento.\n",
        "\n",
        "Este enfoque nos ayuda a evitar errores comunes como el *overfitting* (cuando el modelo aprende demasiado y no generaliza) o el *underfitting* (cuando el modelo no logra captar los patrones relevantes).\n",
        "\n",
        "> Recordá que entrenar un modelo es importante, pero saber **cómo y con qué criterio evaluarlo** es lo que realmente te convierte en una persona capaz de construir soluciones confiables.\n",
        "\n",
        "¡Nos vemos en el próximo cuaderno!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
